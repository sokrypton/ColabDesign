{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sokrypton/ColabDesign/blob/v1.1.1/af/examples/af_pseudo_diffusion_dgram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD9K5H2cnFxL"
      },
      "source": [
        "#AF_pseudo_diffusion + proteinMPNN\n",
        "Hacking AlphaFold to be a diffusion model (for backbone generation) via distogram. At each step add logits from proteinMPNN.\n",
        "\n",
        "\n",
        "- **WARNING**: This notebook is experimental, designed as a control. Not intended for practical use at this stage.\n",
        "- This notebook had a **major update** on 26Dec2022. See [original notebook](https://colab.research.google.com/github/sokrypton/ColabDesign/blob/v1.1.1/af/examples/af_pseudo_diffusion_dgram_old.ipynb) here.\n",
        "- Note: current protocol was optimized for proteins in the length range 100-500."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YCRzPGdTZfEe"
      },
      "outputs": [],
      "source": [
        "#@title setup\n",
        "%%time\n",
        "import os\n",
        "from google.colab import files\n",
        "if not os.path.isdir(\"params\"):\n",
        "  # get code\n",
        "  os.system(\"pip -q install git+https://github.com/sokrypton/ColabDesign.git@v1.1.1\")\n",
        "  # for debugging\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabdesign colabdesign\")\n",
        "  # download params\n",
        "  os.system(\"mkdir params\")\n",
        "  os.system(\"apt-get install aria2 -qq\")\n",
        "  os.system(\"aria2c -q -x 16 https://storage.googleapis.com/alphafold/alphafold_params_2022-03-02.tar\")\n",
        "  os.system(\"tar -xf alphafold_params_2022-03-02.tar -C params\")\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import os, re\n",
        "from colabdesign import mk_afdesign_model, clear_mem\n",
        "from colabdesign.mpnn import mk_mpnn_model\n",
        "from colabdesign.af.alphafold.common import residue_constants\n",
        "from colabdesign.shared.protein import _np_get_cb\n",
        "\n",
        "from IPython.display import HTML\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import jax.numpy as jnp\n",
        "import jax\n",
        "from scipy.special import softmax\n",
        "from scipy.special import expit as sigmoid\n",
        "import tqdm.notebook\n",
        "TQDM_BAR_FORMAT = '{l_bar}{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]'\n",
        "\n",
        "from colabdesign.af.weights import __file__ as af_path\n",
        "template_dgram_head = np.load(os.path.join(os.path.dirname(af_path),'template_dgram_head.npy'))\n",
        "\n",
        "def get_pdb(pdb_code=\"\"):\n",
        "  if pdb_code is None or pdb_code == \"\":\n",
        "    upload_dict = files.upload()\n",
        "    pdb_string = upload_dict[list(upload_dict.keys())[0]]\n",
        "    with open(\"tmp.pdb\",\"wb\") as out: out.write(pdb_string)\n",
        "    return \"tmp.pdb\"\n",
        "  elif os.path.isfile(pdb_code):\n",
        "    return pdb_code\n",
        "  elif len(pdb_code) == 4:\n",
        "    os.system(f\"wget -qnc https://files.rcsb.org/view/{pdb_code}.pdb\")\n",
        "    return f\"{pdb_code}.pdb\"\n",
        "  else:\n",
        "    os.system(f\"wget -qnc https://alphafold.ebi.ac.uk/files/AF-{pdb_code}-F1-model_v3.pdb\")\n",
        "    return f\"AF-{pdb_code}-F1-model_v3.pdb\"\n",
        "\n",
        "def sample_gumbel(shape, sym=False, eps=1e-20): \n",
        "  \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
        "  U = np.random.uniform(size=shape)\n",
        "  o = -np.log(-np.log(U + eps) + eps)\n",
        "  if sym:\n",
        "    i,j = np.triu_indices(o.shape[0],k=1)\n",
        "    o[j,i] = o[i,j]\n",
        "  return o\n",
        "\n",
        "def get_dgram(positions=None, dist=None, num_bins=39, min_bin=3.25, max_bin=50.75):\n",
        "  if dist is None:\n",
        "    atom_idx = residue_constants.atom_order\n",
        "    atoms = {k:positions[...,atom_idx[k],:] for k in [\"N\",\"CA\",\"C\"]}\n",
        "    cb = _np_get_cb(**atoms, use_jax=False)\n",
        "    dist = np.sqrt(np.square(cb[None,:] - cb[:,None]).sum(-1,keepdims=True))\n",
        "  lower_breaks = np.linspace(min_bin, max_bin, num_bins)\n",
        "  lower_breaks = lower_breaks\n",
        "  upper_breaks = np.concatenate([lower_breaks[1:],np.array([1e8], dtype=jnp.float32)], axis=-1)\n",
        "  def get_bins(d):\n",
        "    return ((d > lower_breaks) * (d < upper_breaks)).astype(float)  \n",
        "  return get_bins(dist)\n",
        "\n",
        "def af_diffusion(af_model, mpnn_model,\n",
        "                iterations=100, dgram_noise=0.5, seqsep_mask=6,\n",
        "                use_dropout=True, sample_models=True, num_recycles=1,\n",
        "                mpnn_mode=\"conditional\", mpnn_mask=\"cmap\",\n",
        "                cmap_dist=8.0, cmap_ss=6, cmap_num=1,\n",
        "                starting_seq=\"\", out_pdb=\"init.pdb\", verbose=False):\n",
        "\n",
        "  assert mpnn_mode in [\"none\",\"unconditional\",\"conditional\"]\n",
        "  assert mpnn_mask in [\"cmap\",\"plddt\",\"exp_res\"]\n",
        "  \n",
        "  # restart model\n",
        "  af_model.restart()\n",
        "  l, L = af_model._len, sum(af_model._lengths)\n",
        "  copies = af_model._args[\"copies\"]\n",
        "  af_model.set_opt(alpha=1.0, weights=dict(helix=1e-8))\n",
        "  \n",
        "  # gather info about inputs\n",
        "  if \"offset\" in af_model._inputs:\n",
        "    offset = af_model._inputs[\"offset\"]\n",
        "  else:\n",
        "    idx = af_model._inputs[\"residue_index\"]\n",
        "    offset = idx[:,None] - idx[None,:]\n",
        "\n",
        "  # initialize sequence\n",
        "  if len(starting_seq) > 1:\n",
        "    af_model.set_seq(seq=starting_seq)\n",
        "  else:\n",
        "    af_model.set_seq(sample_gumbel((l,20)))\n",
        "\n",
        "  # initialize coordinates/dgram\n",
        "  af_model._inputs[\"batch\"] = {\"aatype\":np.zeros(L).astype(int),\n",
        "                               \"all_atom_mask\":np.zeros((L,37)),\n",
        "                               \"all_atom_positions\":np.zeros((L,37,3)),\n",
        "                               \"dgram\":np.zeros((L,L,39))}\n",
        "\n",
        "  aux = {\"dgram_logits\":np.zeros((L,L,39))}  \n",
        "  save_best = False\n",
        "  for k in range(iterations):\n",
        "    # disable stochastic part for the last 10 steps\n",
        "    if k > (iterations - 10):\n",
        "      use_dropout = False\n",
        "      sample_models = False\n",
        "      save_best = True\n",
        "      dgram_noise = 0.0\n",
        "    \n",
        "    # noise\n",
        "    noise = sample_gumbel(aux[\"dgram_logits\"].shape, sym=True)\n",
        "    noise = noise * dgram_noise * (1 - k/iterations)\n",
        "    dgram = softmax(aux[\"dgram_logits\"] + noise, -1)\n",
        "\n",
        "    # add mask to avoid local contacts being fixed (otherwise there is a bias toward helix)\n",
        "    dgram_mask = np.abs(offset) > seqsep_mask\n",
        "    af_model._inputs[\"batch\"][\"dgram\"] = dgram * dgram_mask[...,None]\n",
        "\n",
        "    # denoise\n",
        "    aux.update(af_model.predict(return_aux=True,\n",
        "                                verbose=False,\n",
        "                                sample_models=sample_models,\n",
        "                                dropout=use_dropout,\n",
        "                                num_recycles=num_recycles))\n",
        "    \n",
        "    # gather features\n",
        "    plddt = aux[\"plddt\"]\n",
        "    xyz = aux[\"atom_positions\"]\n",
        "    seq = aux[\"seq\"][\"hard\"][0].argmax(-1)\n",
        "    if copies > 1: seq = np.tile(seq, copies)\n",
        "\n",
        "    # update inputs    \n",
        "    af_model._inputs[\"batch\"][\"aatype\"] = seq\n",
        "    af_model._inputs[\"batch\"][\"all_atom_positions\"] = xyz\n",
        "\n",
        "    model_num = aux[\"log\"][\"models\"][0]\n",
        "    dgram_logits = aux[\"prev\"][\"prev_pair\"] @ template_dgram_head[model_num]\n",
        "    dgram_logits += dgram_logits.swapaxes(0,1)\n",
        "    aux[\"dgram_logits\"] = dgram_logits\n",
        "\n",
        "    # per position confidence\n",
        "    if mpnn_mask == \"cmap\":\n",
        "      dgram_bins = np.append(0,np.linspace(2.3125,21.6875,63))\n",
        "      dgram_probs = softmax(aux[\"debug\"][\"outputs\"][\"distogram\"][\"logits\"],-1)\n",
        "      cmap = (dgram_probs * (dgram_bins < cmap_dist)).sum(-1)\n",
        "      conf = np.sort(cmap * (np.abs(offset) > cmap_ss))[:,-cmap_num:].mean(-1)\n",
        "\n",
        "      # WARNING: option under development\n",
        "      if copies > 1:\n",
        "        chain_id = af_model._inputs[\"asym_id\"]\n",
        "        inter_mask = chain_id[:,None] != chain_id[None,:]\n",
        "        i_cmap = dgram_probs[...,:-1].sum(-1)\n",
        "        i_conf = np.sort(i_cmap * inter_mask)[:,-cmap_num:].mean(-1)\n",
        "        conf = 0.5 * conf + 0.5 * i_conf\n",
        "\n",
        "    if mpnn_mask == \"plddt\":\n",
        "      conf = aux[\"plddt\"]\n",
        "\n",
        "    if mpnn_mask == \"exp_res\":\n",
        "      exp_res = sigmoid(aux[\"debug\"][\"outputs\"][\"experimentally_resolved\"][\"logits\"])\n",
        "      conf = exp_res[:,1]\n",
        "              \n",
        "    # add logits from proteinmpnn at each stage\n",
        "    if mpnn_mode != \"none\":    \n",
        "      mpnn_model.get_af_inputs(af_model)\n",
        "      opt = {\"mask\":np.sqrt(conf)}    \n",
        "      if mpnn_mode == \"unconditional\":\n",
        "        opt[\"ar_mask\"] = np.zeros((L,L))\n",
        "      mpnn_out = mpnn_model.score(**opt)\n",
        "      mpnn_logits = mpnn_out[\"logits\"][:l,:20]\n",
        "      aux[\"log\"][\"mpnn\"] = mpnn_out[\"score\"]\n",
        "\n",
        "      # accumulate sequence\n",
        "      c = conf.reshape(copies,-1).mean(0)[:,None]\n",
        "      new_logits = (1 - c) * sample_gumbel((l,20)) + c * mpnn_logits\n",
        "      af_model._params[\"seq\"] = 0.9 * af_model._params[\"seq\"] + 0.1 * new_logits\n",
        "\n",
        "    # save results\n",
        "    af_model._save_results(aux, save_best=save_best, verbose=verbose)\n",
        "    af_model._k += 1\n",
        "\n",
        "  af_model.save_pdb(out_pdb)\n",
        "  return aux\n",
        "\n",
        "def designability_test(af_model_test, mpnn_model_test,\n",
        "                       num_seqs=16, sampling_temp=0.1, num_recycles=3, \n",
        "                       model_num=4, best_metric=\"dgram_cce\",\n",
        "                       in_pdb=\"init.pdb\", out_pdb=\"final.pdb\",\n",
        "                       out_dir=None, verbose=False):\n",
        "  alphafold_model = f\"model_{model_num}_ptm\"\n",
        "\n",
        "  af_model_test.prep_inputs(in_pdb)\n",
        "  af_model_test._args[\"best_metric\"] = best_metric\n",
        "  L = sum(af_model_test._lengths)\n",
        "  mpnn_model_test.get_af_inputs(af_model_test)\n",
        "  out = mpnn_model_test.sample(num=num_seqs//8, batch=8,\n",
        "                               temperature=sampling_temp)\n",
        "\n",
        "  af_terms = [\"plddt\",\"ptm\",\"pae\",\"rmsd\",\"dgram_cce\"]\n",
        "  for k in af_terms: out[k] = []\n",
        "\n",
        "  with tqdm.notebook.tqdm(total=num_seqs, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
        "    for n in range(num_seqs):\n",
        "      seq = out[\"seq\"][n]\n",
        "      af_model_test.predict(seq=seq,\n",
        "                            num_recycles=num_recycles,\n",
        "                            num_models=1,\n",
        "                            verbose=False,\n",
        "                            models=alphafold_model)\n",
        "\n",
        "      for k in af_terms: out[k].append(af_model_test.aux[\"log\"][k])\n",
        "      out[\"pae\"][-1] = out[\"pae\"][-1] * 31\n",
        "      af_model_test._save_results(save_best=True, verbose=verbose)\n",
        "      af_model_test._k += 1\n",
        "      if out_dir is not None:\n",
        "        out_pdb_tmp = os.path.join(os.path.dirname(out_dir), f\"n{n}.pdb\")\n",
        "        af_model_test.save_current_pdb(out_pdb_tmp)\n",
        "      pbar.update(1)\n",
        "\n",
        "  af_model_test.save_pdb(out_pdb)\n",
        "  labels = [\"score\"] + af_terms + [\"seq\"]\n",
        "  data = [[out[k][n] for k in labels] for n in range(num_seqs)]\n",
        "  labels[0] = \"mpnn\"\n",
        "  return pd.DataFrame(data, columns=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxYMB4A9Zmrf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title initialize the model\n",
        "length = 100 #@param {type:\"integer\"}\n",
        "\n",
        "# WARNING: option under development\n",
        "copies = 1 # param {type:\"integer\"}\n",
        "\n",
        "#@markdown Provide a starting point (optional)\n",
        "starting_seq = \"\" #@param {type:\"string\"}\n",
        "starting_seq = re.sub(\"[^A-Z]\", \"\", starting_seq.upper())\n",
        "#@markdown - if `starting_seq` provided the `length` option will be overwritten by length of starting sequence.\n",
        "\n",
        "if len(starting_seq) > 0:\n",
        "  length = len(starting_seq)\n",
        "\n",
        "# initialize the model\n",
        "clear_mem()\n",
        "af_model = mk_afdesign_model(protocol=\"hallucination\",\n",
        "                             use_templates=True,\n",
        "                             debug=True)\n",
        "af_model.prep_inputs(length=length, copies=copies)\n",
        "mpnn_model = mk_mpnn_model()\n",
        "\n",
        "# seperate model for scoring\n",
        "af_model_test = mk_afdesign_model(protocol=\"fixbb\", best_metric=\"dgram_cce\")\n",
        "mpnn_model_test = mk_mpnn_model()\n",
        "  \n",
        "print(\"lengths\",af_model._lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Dt8i00UbxtW",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title run protocol\n",
        "#@markdown Optimization options\n",
        "iterations = 100 #@param [\"50\", \"100\", \"200\"] {type:\"raw\"}\n",
        "dgram_noise = 0.5 #@param [\"0.1\", \"0.2\", \"0.5\", \"1.0\"] {type:\"raw\"}\n",
        "seqsep_mask = 6 #@param [\"0\", \"6\", \"12\"] {type:\"raw\"}\n",
        "\n",
        "#@markdown AlphaFold options\n",
        "use_dropout = True #@param {type:\"boolean\"}\n",
        "sample_models = True #@param {type:\"boolean\"}\n",
        "num_recycles = 1 #@param [\"0\", \"1\", \"2\", \"3\"] {type:\"raw\"}\n",
        "\n",
        "#@markdown proteinMPNN options (set to `none` to disable)\n",
        "mpnn_mode = \"conditional\" #@param [\"none\", \"unconditional\", \"conditional\"]\n",
        "mpnn_mask = \"cmap\" #@param [\"cmap\", \"plddt\", \"exp_res\"]\n",
        "\n",
        "aux = af_diffusion(af_model, mpnn_model,\n",
        "                  iterations=iterations,\n",
        "                  dgram_noise=dgram_noise,\n",
        "                  seqsep_mask=seqsep_mask,\n",
        "                  use_dropout=use_dropout,\n",
        "                  sample_models=sample_models,\n",
        "                  num_recycles=num_recycles,\n",
        "                  mpnn_mode=mpnn_mode, mpnn_mask=mpnn_mask,\n",
        "                  cmap_dist=8.0, cmap_ss=6, cmap_num=1,\n",
        "                  starting_seq=starting_seq,\n",
        "                  out_pdb=\"init.pdb\", verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af_model.plot_pdb()\n",
        "af_model.get_seqs()"
      ],
      "metadata": {
        "id": "YeYD4KF8MUA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cJhizcYcUxm"
      },
      "outputs": [],
      "source": [
        "HTML(af_model.animate(dpi=100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title sample new sequences using proteinMPNN and rescore with alphafold (w/o template)\n",
        "import pandas as pd\n",
        "from google.colab import data_table\n",
        "from colabdesign.shared.protein import alphabet_list as chain_list\n",
        "data_table.enable_dataframe_formatter()\n",
        "os.system(\"mkdir -p output/all_pdb\")\n",
        "\n",
        "#@markdown #### Design Options\n",
        "num_seqs = 16 #@param [\"8\", \"16\", \"32\"] {type:\"raw\"}\n",
        "sampling_temp = 0.1 \n",
        "num_recycles = 3 #@param [\"0\", \"1\", \"2\", \"3\"] {type:\"raw\"}\n",
        "model_num = 4 #@param [\"1\", \"2\", \"3\", \"4\", \"5\"] {type:\"raw\"}\n",
        "alphafold_model = f\"model_{model_num}_ptm\"\n",
        "\n",
        "af_model_test.prep_inputs(f\"init.pdb\",\n",
        "                          chain=\",\".join(chain_list[:copies]),\n",
        "                          copies=copies,\n",
        "                          homooligomer=copies>1)\n",
        "\n",
        "mpnn_model_test.get_af_inputs(af_model_test)\n",
        "out = mpnn_model_test.sample(num=num_seqs//8, batch=8,\n",
        "                              temperature=sampling_temp)\n",
        "\n",
        "df = designability_test(af_model_test, mpnn_model_test,\n",
        "                        num_seqs=num_seqs, sampling_temp=sampling_temp, num_recycles=3, \n",
        "                        model_num=model_num, best_metric=\"dgram_cce\",\n",
        "                        in_pdb=\"init.pdb\", out_pdb=\"final.pdb\",\n",
        "                        out_dir=\"output/all_pdb\", verbose=False)\n",
        "df.to_csv('output/mpnn_results.csv')\n",
        "data_table.DataTable(df.round(3).sort_values(\"dgram_cce\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3H_B0AoYIiWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3dPQeEQcAcT"
      },
      "outputs": [],
      "source": [
        "af_model_test.plot_pdb()\n",
        "af_model_test.get_seqs()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
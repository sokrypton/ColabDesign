{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sokrypton/ColabDesign/blob/v1.1.1/af/examples/use_esm_1b_bias.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gather inputs"
      ],
      "metadata": {
        "id": "M9xamJDvx1pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, re\n",
        "from google.colab import files\n",
        "\n",
        "def get_uniprot_seq(uid):\n",
        "  url = f'https://rest.uniprot.org/uniprotkb/stream?compressed=false&format=fasta&query={uid}'\n",
        "  sequence = \"\".join(re.split(r'\\n(?=>)', requests.get(url).text)[0].split(\"\\n\")[1:])\n",
        "  return sequence\n",
        "\n",
        "def get_pdb(pdb_code=\"\",alphafold_model=False):\n",
        "  if pdb_code is None or pdb_code == \"\":\n",
        "    upload_dict = files.upload()\n",
        "    pdb_string = upload_dict[list(upload_dict.keys())[0]]\n",
        "    with open(\"tmp.pdb\",\"wb\") as out: out.write(pdb_string)\n",
        "    return \"tmp.pdb\"\n",
        "  else:\n",
        "    if alphafold_model:\n",
        "      os.system(f\"wget -qnc https://alphafold.ebi.ac.uk/files/AF-{pdb_code}-F1-model_v3.pdb\")\n",
        "      return f\"AF-{pdb_code}-F1-model_v3.pdb\"      \n",
        "    else:\n",
        "      os.system(f\"wget -qnc https://files.rcsb.org/view/{pdb_code}.pdb\")\n",
        "      return f\"{pdb_code}.pdb\""
      ],
      "metadata": {
        "id": "lev6Nc_-vx2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UNIPROT = \"P0A6A8\"\n",
        "SEQUENCE = get_uniprot_seq(UNIPROT)\n",
        "PDB_FILENAME = get_pdb(UNIPROT, alphafold_model=True)"
      ],
      "metadata": {
        "id": "VkPdQj-Fv1LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5LVw2BwijkB"
      },
      "source": [
        "#ESM_1b\n",
        "use logits from ESM_1b as prior to AfDesign"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j12AU-SikvN"
      },
      "outputs": [],
      "source": [
        "!pip -q install fair-esm\n",
        "import esm\n",
        "import gc\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63LNj3dHilRW"
      },
      "outputs": [],
      "source": [
        "model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
        "\n",
        "# run model on GPU if available\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "model = model.eval()\n",
        "model.args.token_dropout = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ql8K460bjQtv"
      },
      "outputs": [],
      "source": [
        "def get_bias_from_esm(seq, p=None):\n",
        "  '''p=None; number of calculation done in parallel (increase if you have more gpu-memory)'''\n",
        "\n",
        "  # map esm-alphabet to standard-alphabet\n",
        "  tmp_a2n = {a:n for n,a in enumerate(alphabet.all_toks[4:24])}\n",
        "  tmp_aa_map = np.array([tmp_a2n[a] for a in \"ARNDCQEGHILKMFPSTWYV\"])\n",
        "\n",
        "  x,ln = alphabet.get_batch_converter()([(None,seq)])[-1],len(seq)\n",
        "  if p is None: p = ln\n",
        "  with torch.no_grad():\n",
        "    f = lambda x: model(x)[\"logits\"][:,1:(ln+1),4:24]\n",
        "    logits = np.zeros((ln,20))\n",
        "    for n in range(0,ln,p):\n",
        "      m = min(n+p,ln)\n",
        "      x_h = torch.tile(torch.clone(x),[m-n,1])\n",
        "      for i in range(m-n):\n",
        "        x_h[i,n+i+1] = alphabet.mask_idx\n",
        "      fx_h = f(x_h.to(device))\n",
        "      for i in range(m-n):\n",
        "        logits[n+i] = fx_h[i,n+i].cpu().numpy()\n",
        "  \n",
        "    return logits[:,tmp_aa_map]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrD1PRRMkZt3"
      },
      "outputs": [],
      "source": [
        "# get bias\n",
        "seq = SEQUENCE\n",
        "bias = get_bias_from_esm(seq)\n",
        "np.savetxt(\"bias.txt\",bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_8S9rXOkwZ8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(bias.T,cmap=\"bwr_r\",vmin=-10,vmax=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clear GPU memory\n",
        "del model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "10_kZfNQJpsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA2k3sAYuiXe"
      },
      "source": [
        "#AfDesign \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-AXy0s_4cKaK"
      },
      "outputs": [],
      "source": [
        "#@title setup afdesign\n",
        "%%time\n",
        "import os\n",
        "if not os.path.isdir(\"params\"):\n",
        "  # get code\n",
        "  os.system(\"pip -q install git+https://github.com/sokrypton/ColabDesign.git@v1.1.1\")\n",
        "  # for debugging\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabdesign colabdesign\")\n",
        "  # download params\n",
        "  os.system(\"mkdir params\")\n",
        "  os.system(\"apt-get install aria2 -qq\")\n",
        "  os.system(\"aria2c -q -x 16 https://storage.googleapis.com/alphafold/alphafold_params_2022-12-06.tar\")\n",
        "  os.system(\"tar -xf alphafold_params_2022-12-06.tar -C params\")\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import os\n",
        "from colabdesign import mk_afdesign_model, clear_mem\n",
        "from colabdesign.af.alphafold.common import residue_constants\n",
        "from IPython.display import HTML\n",
        "import numpy as np\n",
        "\n"
      ]

    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLd1DsnKzxBJ"
      },
      "outputs": [],
      "source": [
        "clear_mem()\n",
        "model = mk_afdesign_model(protocol=\"fixbb\",\n",
        "                          use_templates=False) # set True to constrain structure\n",
        "model.prep_inputs(PDB_FILENAME, chain=\"A\")\n",
        "print(\"length\",  model._len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZGyGfMTmdXE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "bias = np.loadtxt(\"bias.txt\")\n",
        "plt.imshow(bias.T,cmap=\"bwr_r\",vmin=-10,vmax=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeVuwTYWmQmp"
      },
      "outputs": [],
      "source": [
        "model.restart()\n",
        "model.set_seq(bias=bias)\n",
        "model.design_3stage(50,50,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cW1KQiHKJpfp"
      },
      "outputs": [],
      "source": [
        "HTML(model.animate())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDrChASGVUUx"
      },
      "outputs": [],
      "source": [
        "model.get_seqs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEApO8YzBoS0"
      },
      "outputs": [],
      "source": [
        "model.save_pdb(f\"{model.protocol}.pdb\")\n",
        "model.plot_pdb()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Xd7zQ-PqTly"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "q4qiU9I0QHSz"
      ],
      "name": "use_esm_1b_bias.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}